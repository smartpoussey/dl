# ***************************************************
# XOR Multilayer backpropagation
import numpy as np
import matplotlib.pyplot as plt

# -------------------------
# Activation functions
# -------------------------
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

# -------------------------
# Neural Network Class
# -------------------------
class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.1):
        # Xavier initialization
        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1. / input_size)
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)
        self.b2 = np.zeros((1, output_size))
        self.lr = learning_rate
        self.loss_history = []

    def forward(self, X):
        self.Z1 = np.dot(X, self.W1) + self.b1
        self.A1 = sigmoid(self.Z1)
        self.Z2 = np.dot(self.A1, self.W2) + self.b2
        self.A2 = sigmoid(self.Z2)
        return self.A2

    def backward(self, X, y, output):
        m = X.shape[0]
        dA2 = output - y
        dZ2 = dA2 * sigmoid_derivative(output)
        dW2 = np.dot(self.A1.T, dZ2) / m
        db2 = np.sum(dZ2, axis=0, keepdims=True) / m

        dA1 = np.dot(dZ2, self.W2.T)
        dZ1 = dA1 * sigmoid_derivative(self.A1)
        dW1 = np.dot(X.T, dZ1) / m
        db1 = np.sum(dZ1, axis=0, keepdims=True) / m

        # Update parameters
        self.W1 -= self.lr * dW1
        self.b1 -= self.lr * db1
        self.W2 -= self.lr * dW2
        self.b2 -= self.lr * db2

    def train(self, X, y, epochs=10000):
        for epoch in range(epochs):
            output = self.forward(X)
            loss = np.mean((y - output) ** 2)
            self.loss_history.append(loss)
            self.backward(X, y, output)
            if epoch % 1000 == 0:
                print(f"Epoch {epoch}, Loss: {loss:.4f}")

    def predict(self, X):
        return np.round(self.forward(X))

# -------------------------
# XOR Dataset
# -------------------------
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([[0],[1],[1],[0]])

# -------------------------
# Train the network
# -------------------------
nn = NeuralNetwork(input_size=2, hidden_size=4, output_size=1, learning_rate=0.5)
nn.train(X, y, epochs=10000)

# Predictions
print("\nPredictions:")
print(nn.forward(X))

# -------------------------
# Visualization
# -------------------------

# 1. Loss curve
plt.figure(figsize=(12,4))
plt.subplot(1,3,1)
plt.plot(nn.loss_history)
plt.title("Loss Curve")
plt.xlabel("Epochs")
plt.ylabel("Loss")

# 2. Predicted vs Actual
plt.subplot(1,3,2)
plt.scatter(range(len(y)), y, color='red', label="Actual")
plt.scatter(range(len(y)), nn.forward(X), color='blue', marker='x', label="Predicted")
plt.title("Predicted vs Actual")
plt.legend()

# 3. Decision Boundary
plt.subplot(1,3,3)
xx, yy = np.meshgrid(np.linspace(0,1,100), np.linspace(0,1,100))
grid = np.c_[xx.ravel(), yy.ravel()]
probs = nn.forward(grid).reshape(xx.shape)
plt.contourf(xx, yy, probs, levels=[0,0.5,1], alpha=0.6, cmap="bwr")
plt.scatter(X[:,0], X[:,1], c=y.ravel(), edgecolors="k", cmap="bwr", s=100)
plt.title("Decision Boundary")

plt.tight_layout()
plt.show()


# ----------------------------------------
import numpy as np
import matplotlib.pyplot as plt

# -------------------------
# XOR dataset
# -------------------------
X = np.array([[0,0],[0,1],[1,0],[1,1]])
y = np.array([0,1,1,0], dtype=float)

# -------------------------
# Simple greedy regression tree (procedural, depth-limited)
# Tree is represented as nested dictionaries.
# -------------------------
def find_best_split(X, y):
    m, n_features = X.shape
    best_loss = float('inf')
    best = None

    for feat in range(n_features):
        values = np.unique(X[:, feat])
        # consider thresholds as midpoints between sorted unique values
        thresholds = []
        if values.size == 1:
            thresholds = [values[0]]
        else:
            values_sorted = np.sort(values)
            thresholds = (values_sorted[:-1] + values_sorted[1:]) / 2.0

        for thr in thresholds:
            left_mask = X[:, feat] <= thr
            right_mask = ~left_mask

            if not np.any(left_mask) or not np.any(right_mask):
                continue

            left_mean = np.mean(y[left_mask]) if np.any(left_mask) else 0.0
            right_mean = np.mean(y[right_mask]) if np.any(right_mask) else 0.0

            pred = np.where(left_mask, left_mean, right_mean)
            loss = np.mean((y - pred)**2)

            if loss < best_loss:
                best_loss = loss
                best = {
                    "feature": feat,
                    "threshold": thr,
                    "left_value": left_mean,
                    "right_value": right_mean,
                    "loss": loss
                }
    return best

def build_tree(X, y, depth=0, max_depth=2, min_samples_split=1):
    node = {}
    m = X.shape[0]

    # stopping criteria
    if depth >= max_depth or m <= min_samples_split or np.allclose(y, y[0]):
        node["is_leaf"] = True
        node["value"] = float(np.mean(y))
        return node

    split = find_best_split(X, y)
    if split is None:
        node["is_leaf"] = True
        node["value"] = float(np.mean(y))
        return node

    # create internal node
    node["is_leaf"] = False
    node["feature"] = split["feature"]
    node["threshold"] = split["threshold"]

    left_mask = X[:, node["feature"]] <= node["threshold"]
    right_mask = ~left_mask

    # If a split does not separate, make leaf
    if not np.any(left_mask) or not np.any(right_mask):
        node["is_leaf"] = True
        node["value"] = float(np.mean(y))
        return node

    node["left"] = build_tree(X[left_mask], y[left_mask], depth+1, max_depth, min_samples_split)
    node["right"] = build_tree(X[right_mask], y[right_mask], depth+1, max_depth, min_samples_split)
    return node

def predict_tree(node, X):
    # X: (m, n)
    m = X.shape[0]
    preds = np.zeros(m, dtype=float)

    def traverse(i, row, nd):
        if nd["is_leaf"]:
            return nd["value"]
        if row[nd["feature"]] <= nd["threshold"]:
            return traverse(i, row, nd["left"])
        else:
            return traverse(i, row, nd["right"])

    for i in range(m):
        preds[i] = traverse(i, X[i], node)
    return preds

# ***************************************************
# Gradient Boosting
# -------------------------
def gradient_boosting_fit(X, y, n_estimators=20, learning_rate=0.3, max_depth=2):
    m = X.shape[0]
    F0 = np.mean(y)  # initial constant prediction
    preds = np.full(m, F0, dtype=float)
    trees = []
    loss_history = []

    for it in range(n_estimators):
        residuals = y - preds  # fit residuals (MSE)
        # fit a regression tree to residuals
        tree = build_tree(X, residuals, depth=0, max_depth=max_depth)
        update = predict_tree(tree, X)
        preds += learning_rate * update
        trees.append(tree)

        loss = np.mean((y - preds)**2)
        loss_history.append(loss)
        if it % 5 == 0 or it == n_estimators-1:
            print(f"Iter {it:3d}: Loss = {loss:.6f}")
    return F0, trees, loss_history

def gradient_boosting_predict(X, F0, trees, learning_rate=0.3):
    m = X.shape[0]
    preds = np.full(m, F0, dtype=float)
    for tree in trees:
        preds += learning_rate * predict_tree(tree, X)
    return preds

# -------------------------
# Train on XOR
# -------------------------
np.random.seed(42)
F0, trees, loss_history = gradient_boosting_fit(X, y, n_estimators=50, learning_rate=0.5, max_depth=2)

final_preds = gradient_boosting_predict(X, F0, trees, learning_rate=0.5)
print("\nFinal predictions (regression outputs):", np.round(final_preds, 4))
print("Rounded to 0/1:", (final_preds >= 0.5).astype(int))

# -------------------------
# Visualizations
# -------------------------
plt.figure(figsize=(14,4))

# 1) Loss curve
plt.subplot(1,3,1)
plt.plot(loss_history, marker='o')
plt.xlabel("Iteration")
plt.ylabel("MSE Loss")
plt.title("Gradient Boosting Loss Curve")

# 2) Predicted vs Actual
plt.subplot(1,3,2)
plt.scatter(range(len(y)), y, color='C3', label='Actual', s=100)
plt.scatter(range(len(final_preds)), final_preds, color='C0', marker='x', label='Predicted (reg)', s=100)
plt.hlines(0.5, -0.5, 3.5, linestyles='dashed', colors='gray', label='0.5 threshold')
plt.ylim(-0.1, 1.1)
plt.title("Predicted vs Actual")
plt.xlabel("Sample index")
plt.legend()

# 3) Decision boundary (grid)
plt.subplot(1,3,3)
xx, yy = np.meshgrid(np.linspace(-0.2,1.2,200), np.linspace(-0.2,1.2,200))
grid = np.c_[xx.ravel(), yy.ravel()]
grid_preds = gradient_boosting_predict(grid, F0, trees, learning_rate=0.5).reshape(xx.shape)
plt.contourf(xx, yy, grid_preds, levels=[-0.1,0.5,1.1], cmap="bwr", alpha=0.6)
plt.scatter(X[:,0], X[:,1], c=y, edgecolors='k', cmap="bwr", s=120)
plt.title("Decision Boundary (pred >= 0.5 => class 1)")
plt.tight_layout()
plt.show()


# ***************************************************
# Computational Graph
import numpy as np

# -------------------------
# Minimal, correct computational graph
# -------------------------

class Node:
    """Base class for nodes in the graph."""
    def __init__(self, *inputs, name=None):
        self.inputs = list(inputs)
        self.output = None   # will hold forward value (scalar or ndarray)
        self.grad = 0.0      # gradient accumulated during backward
        self.name = name if name is not None else self.__class__.__name__

    def compute(self):
        """Compute output using inputs' .output values (do not call inputs' compute here)."""
        raise NotImplementedError

    def backprop(self):
        """Use self.grad to contribute to inputs' .grad values."""
        raise NotImplementedError

    def __repr__(self):
        return f"<{self.name}>"


class Placeholder(Node):
    def __init__(self, name="Placeholder"):
        super().__init__(name=name)
        self.value = None

    def set_value(self, v):
        self.value = v

    def compute(self):
        self.output = self.value
        return self.output

    def backprop(self):
        # placeholder just accumulates grad in self.grad
        return


class Add(Node):
    def compute(self):
        s = None
        for inp in self.inputs:
            if s is None:
                s = inp.output
            else:
                s = s + inp.output
        self.output = s
        return self.output

    def backprop(self):
        # d/dx (x + y + ...) = 1 for each input
        for inp in self.inputs:
            inp.grad = inp.grad + self.grad


class Multiply(Node):
    def compute(self):
        # supports exactly two inputs
        a = self.inputs[0].output
        b = self.inputs[1].output
        self.output = a * b
        return self.output

    def backprop(self):
        a = self.inputs[0].output
        b = self.inputs[1].output
        # d/d a = grad * b ; d/d b = grad * a
        self.inputs[0].grad = self.inputs[0].grad + self.grad * b
        self.inputs[1].grad = self.inputs[1].grad + self.grad * a


class Power(Node):
    def __init__(self, input_node, exponent, name=None):
        super().__init__(input_node, name=name)
        self.exponent = exponent

    def compute(self):
        x = self.inputs[0].output
        self.output = x ** self.exponent
        return self.output

    def backprop(self):
        x = self.inputs[0].output
        # d/dx x^n = n * x^(n-1)
        self.inputs[0].grad = self.inputs[0].grad + self.grad * self.exponent * (x ** (self.exponent - 1))


class Sigmoid(Node):
    def compute(self):
        x = self.inputs[0].output
        # numerically stable sigmoid
        self.output = 1.0 / (1.0 + np.exp(-x))
        return self.output

    def backprop(self):
        s = self.output
        self.inputs[0].grad = self.inputs[0].grad + self.grad * s * (1 - s)


# -------------------------
# Utilities: topo sort, forward, backward
# -------------------------

def topo_sort(output_node):
    """Return a list of nodes in topological order (inputs before dependents)."""
    visited = set()
    order = []

    def dfs(n):
        if id(n) in visited:
            return
        visited.add(id(n))
        for inp in n.inputs:
            dfs(inp)
        order.append(n)

    dfs(output_node)
    return order


def forward_backward(output_node, seed_grad=1.0):
    """
    Compute forward outputs for entire graph and run backward pass.
    Returns nodes in topological order.
    """
    nodes = topo_sort(output_node)

    # Forward: compute outputs in topo order
    for n in nodes:
        n.compute()

    # Clear previous grads
    for n in nodes:
        n.grad = 0.0

    # Seed gradient for final node (d output / d output)
    output_node.grad = seed_grad

    # Backward: traverse in reverse topo order
    for n in reversed(nodes):
        n.backprop()

    return nodes


# -------------------------
# Example: z = sigmoid((x + y) * x^2)
# -------------------------

if __name__ == "__main__":
    # placeholders
    x = Placeholder(name="x")
    y = Placeholder(name="y")

    # graph construction
    add_node = Add(x, y, name="Add(x,y)")
    square_node = Power(x, 2, name="x^2")
    mul_node = Multiply(add_node, square_node, name="(x+y)*x^2")
    z = Sigmoid(mul_node, name="sigmoid(z)")

    # assign values
    x.set_value(2.0)
    y.set_value(3.0)

    # run forward + backward
    nodes = forward_backward(z, seed_grad=1.0)

    # results
    print("Forward output z =", z.output)
    print("Gradient dz/dx =", x.grad)
    print("Gradient dz/dy =", y.grad)

    # Analytical check (for scalar inputs)
    u = (x.value + y.value) * (x.value ** 2)    # u = (x+y)*x^2
    s = 1.0 / (1.0 + np.exp(-u))
    ds_du = s * (1 - s)
    du_dx = 3 * (x.value ** 2) + 2 * x.value * y.value   # derivative of x^3 + x^2*y
    du_dy = x.value ** 2
    print("\nAnalytical check (expected):")
    print("sigmoid(u) =", s)
    print("dz/dx (analytical) =", ds_du * du_dx)
    print("dz/dy (analytical) =", ds_du * du_dy)



# ***************************************************
# Neural networks

import numpy as np
import matplotlib.pyplot as plt


# ----------------------------
class NeuralNetwork:
    """
    Small 2-layer MLP (one hidden layer) for binary classification.
    - X shape: (m, n_features)
    - W1 shape: (n_features, n_hidden)
    - W2 shape: (n_hidden, 1)
    Uses sigmoid activations and binary cross-entropy loss.
    """
    def __init__(self, n_input, n_hidden, seed=None):
        if seed is not None:
            np.random.seed(seed)
        # Xavier initialization for sigmoid/tanh hidden activations
        limit_w1 = np.sqrt(1.0 / n_input)
        limit_w2 = np.sqrt(1.0 / n_hidden)
        self.W1 = np.random.randn(n_input, n_hidden) * limit_w1
        self.b1 = np.zeros((1, n_hidden))
        self.W2 = np.random.randn(n_hidden, 1) * limit_w2
        self.b2 = np.zeros((1, 1))
        self.loss_history = []

    # ---- activations ----
    @staticmethod
    def sigmoid(z):
        return 1.0 / (1.0 + np.exp(-z))

    @staticmethod
    def dsigmoid(a):
        # a is sigmoid(z)
        return a * (1 - a)

    # ---- forward pass ----
    def forward(self, X):
        """
        X: (m, n_input)
        returns: A2 (m,1)
        saves intermediate A1 for backward
        """
        self.X = X                              # cache
        self.Z1 = X.dot(self.W1) + self.b1      # (m, n_hidden)
        self.A1 = NeuralNetwork.sigmoid(self.Z1)
        self.Z2 = self.A1.dot(self.W2) + self.b2  # (m,1)
        self.A2 = NeuralNetwork.sigmoid(self.Z2)
        return self.A2

    # ---- loss (binary cross-entropy) ----
    @staticmethod
    def compute_loss(y, A2):
        """
        y shape: (m,) or (m,1)
        A2 shape: (m,1)
        returns scalar loss
        """
        m = y.shape[0]
        eps = 1e-8
        y = y.reshape(-1, 1)
        loss = - (1.0 / m) * np.sum(y * np.log(A2 + eps) + (1 - y) * np.log(1 - A2 + eps))
        return loss

    # ---- backward pass ----
    def backward(self, y):
        """
        Compute gradients and store as attributes:
         - dW1, db1, dW2, db2
        Uses the analytical gradient for BCE + sigmoid output:
           dZ2 = (A2 - y) / m
        """
        m = self.X.shape[0]
        y = y.reshape(-1, 1)  # (m,1)

        # dZ2 (m,1)
        dZ2 = (self.A2 - y) / m

        # dW2 (n_hidden, 1)
        self.dW2 = self.A1.T.dot(dZ2)          # (n_hidden,1)
        self.db2 = np.sum(dZ2, axis=0, keepdims=True)  # (1,1)

        # backprop to hidden
        dA1 = dZ2.dot(self.W2.T)               # (m, n_hidden)
        dZ1 = dA1 * NeuralNetwork.dsigmoid(self.A1)  # (m, n_hidden)

        self.dW1 = self.X.T.dot(dZ1)           # (n_input, n_hidden)
        self.db1 = np.sum(dZ1, axis=0, keepdims=True)  # (1, n_hidden)

    # ---- parameter update ----
    def update(self, lr=0.1):
        self.W1 -= lr * self.dW1
        self.b1 -= lr * self.db1
        self.W2 -= lr * self.dW2
        self.b2 -= lr * self.db2

    # ---- training loop ----
    def fit(self, X, y, epochs=10000, lr=0.1, verbose=True, print_every=1000):
        """
        Train using full-batch gradient descent.
        """
        self.loss_history = []
        for ep in range(1, epochs + 1):
            A2 = self.forward(X)                     # forward
            loss = NeuralNetwork.compute_loss(y, A2)
            self.loss_history.append(loss)
            self.backward(y)                         # gradients
            self.update(lr)                          # gradient step

            if verbose and (ep % print_every == 0 or ep == 1 or ep == epochs):
                pred = (A2 >= 0.5).astype(int)
                acc = np.mean(pred.reshape(-1) == y.reshape(-1))
                print(f"Epoch {ep:5d}  Loss: {loss:.6f}  Acc: {acc*100:.2f}%")

    # ---- predict helpers ----
    def predict_proba(self, X):
        return self.forward(X).flatten()

    def predict(self, X, threshold=0.5):
        return (self.predict_proba(X) >= threshold).astype(int)

    def accuracy(self, X, y, threshold=0.5):
        return np.mean(self.predict(X, threshold) == y.reshape(-1))


# ----------------------------
# Bias-Variance estimation
# ----------------------------
def bias_variance_tradeoff(X, y, epoch_list, k=20, hidden_size=4, lr=0.1):
    """
    For each epoch value in epoch_list:
      - train k separate networks (different inits)
      - collect predictions on X
      - compute bias and variance:
         bias = mean_over_samples( (y - mean_pred)^2 )
         variance = mean_over_samples( var_across_models(preds) )
    Returns (epoch_list, biases, variances)
    """
    m = X.shape[0]
    biases = []
    variances = []

    for ep in epoch_list:
        all_preds = np.zeros((k, m), dtype=float)
        for i in range(k):
            nn = NeuralNetwork(n_input=2, n_hidden=hidden_size, seed=None)
            # keep verbose=False for speed
            nn.fit(X, y, epochs=ep, lr=lr, verbose=False)
            all_preds[i, :] = nn.predict_proba(X)  # probabilities

        mean_preds = all_preds.mean(axis=0)          # (m,)
        bias = np.mean((y - mean_preds) ** 2)
        var = np.mean(np.var(all_preds, axis=0))
        biases.append(bias)
        variances.append(var)

    return biases, variances

# ----------------------------
# Plot helpers
# ----------------------------
def plot_loss(loss_history):
    plt.figure(figsize=(6, 4))
    plt.plot(loss_history)
    plt.xlabel("Epoch")
    plt.ylabel("Binary Cross-Entropy Loss")
    plt.title("Training Loss Curve")
    plt.grid(True)
    plt.show()

def plot_pred_vs_actual(y_true, y_prob):
    y_true = y_true.reshape(-1)
    y_prob = np.array(y_prob).reshape(-1)
    y_pred = (y_prob >= 0.5).astype(int)

    plt.figure(figsize=(6, 4))
    idx = np.arange(len(y_true))
    plt.scatter(idx, y_true, label="Actual (0/1)", s=100, marker='o', edgecolors='k')
    plt.scatter(idx, y_prob, label="Predicted prob", s=80, marker='x')
    for i in idx:
        plt.plot([i, i], [y_true[i], y_prob[i]], color='gray', linewidth=0.8, alpha=0.6)
    plt.ylim(-0.1, 1.1)
    plt.xlabel("Sample index")
    plt.ylabel("Target / Predicted probability")
    plt.title("Predicted vs Actual (probabilities & labels)")
    plt.legend()
    plt.grid(True)
    plt.show()

def plot_bias_variance(epoch_list, biases, variances):
    plt.figure(figsize=(6, 4))
    plt.plot(epoch_list, biases, marker='o', label="Bias (squared error)")
    plt.plot(epoch_list, variances, marker='x', label="Variance")
    plt.xlabel("Epochs (model complexity proxy)")
    plt.ylabel("Error component")
    plt.title("Bias-Variance Tradeoff (estimated over multiple inits)")
    plt.legend()
    plt.grid(True)
    plt.show()


# ----------------------------
# Demo run on XOR
# ----------------------------
if __name__ == "__main__":
    # XOR data (4 samples)
    X = np.array([[0, 0],
                  [0, 1],
                  [1, 0],
                  [1, 1]], dtype=float)
    y = np.array([0, 1, 1, 0], dtype=int)

    # Create, train, evaluate
    nn = NeuralNetwork(n_input=2, n_hidden=4, seed=42)
    nn.fit(X, y, epochs=10000, lr=0.5, verbose=True, print_every=2000)

    probs = nn.predict_proba(X)
    preds = nn.predict(X)
    acc = nn.accuracy(X, y)

    print("\nFinal predicted probabilities (4 samples):")
    print(np.round(probs, 6))
    print("Final binary predictions:")
    print(preds.reshape(-1))
    print(f"Training accuracy on XOR: {acc*100:.2f}%")

    # ---- Plots ----
    # 1) Loss curve
    plot_loss(nn.loss_history)

    # 2) Predicted vs Actual
    plot_pred_vs_actual(y, probs)

    # 3) Bias-Variance tradeoff
    epoch_list = [10, 50, 100, 500, 2000]    # smaller list is fine for XOR; adjust if you want
    biases, variances = bias_variance_tradeoff(X, y, epoch_list, k=20, hidden_size=4, lr=0.5)
    plot_bias_variance(epoch_list, biases, variances)


# ***************************************************
# Optimization:
# Optimizers -Adagrad,Momentum,Adam etc..

import numpy as np
import matplotlib.pyplot as plt

# -----------------------------
# Toy function: f(x, y) = x^2 + y^2
# -----------------------------
def f(x, y):
    return x**2 + y**2

def grad_f(x, y):
    return np.array([2*x, 2*y])

# -----------------------------
# Optimizers
# -----------------------------
def sgd(xy, grad, lr):
    return xy - lr * grad

def momentum(xy, grad, v, lr, beta=0.9):
    v = beta * v + lr * grad
    return xy - v, v

def adagrad(xy, grad, G, lr, eps=1e-8):
    G += grad**2
    adjusted = lr / (np.sqrt(G) + eps)
    return xy - adjusted * grad, G

def rmsprop(xy, grad, E, lr, beta=0.9, eps=1e-8):
    E = beta * E + (1-beta) * grad**2
    adjusted = lr / (np.sqrt(E) + eps)
    return xy - adjusted * grad, E

def adam(xy, grad, m, v, t, lr, beta1=0.9, beta2=0.999, eps=1e-8):
    m = beta1 * m + (1-beta1) * grad
    v = beta2 * v + (1-beta2) * (grad**2)
    m_hat = m / (1 - beta1**t)
    v_hat = v / (1 - beta2**t)
    xy = xy - lr * m_hat / (np.sqrt(v_hat) + eps)
    return xy, m, v

# -----------------------------
# Run experiment
# -----------------------------
def run_optimizer(opt_name, lr=0.1, steps=50):
    xy = np.array([2.5, 2.5])  # starting point
    history = [xy.copy()]
    v = np.zeros_like(xy)
    G = np.zeros_like(xy)
    E = np.zeros_like(xy)
    m = np.zeros_like(xy)
    v_adam = np.zeros_like(xy)

    for t in range(1, steps+1):
        grad = grad_f(*xy)

        if opt_name == "sgd":
            xy = sgd(xy, grad, lr)

        elif opt_name == "momentum":
            xy, v = momentum(xy, grad, v, lr)

        elif opt_name == "adagrad":
            xy, G = adagrad(xy, grad, G, lr)

        elif opt_name == "rmsprop":
            xy, E = rmsprop(xy, grad, E, lr)

        elif opt_name == "adam":
            xy, m, v_adam = adam(xy, grad, m, v_adam, t, lr)

        history.append(xy.copy())

    return np.array(history)

# -----------------------------
# Main visualization
# -----------------------------
optimizers = ["sgd", "momentum", "adagrad", "rmsprop", "adam"]
colors = ["red", "blue", "green", "purple", "orange"]

# Contour setup
x = np.linspace(-3, 3, 200)
y = np.linspace(-3, 3, 200)
X, Y = np.meshgrid(x, y)
Z = f(X, Y)

# (1) Combined comparison plots
plt.figure(figsize=(14,6))

# Trajectories
plt.subplot(1,2,1)
plt.contour(X, Y, Z, levels=30, cmap="gray")
for opt, c in zip(optimizers, colors):
    hist = run_optimizer(opt, lr=0.1, steps=30)
    plt.plot(hist[:,0], hist[:,1], marker="o", markersize=3, color=c, label=opt)
plt.title("Optimization paths on f(x,y)=x²+y²")
plt.legend()

# Loss curves
plt.subplot(1,2,2)
for opt, c in zip(optimizers, colors):
    hist = run_optimizer(opt, lr=0.1, steps=30)
    losses = [f(pt[0], pt[1]) for pt in hist]
    plt.plot(losses, color=c, label=opt)
plt.yscale("log")
plt.xlabel("Iteration")
plt.ylabel("Loss (log scale)")
plt.title("Loss curves (comparison)")
plt.legend()

plt.tight_layout()
plt.show()

# (2) Individual optimizer plots
for opt, c in zip(optimizers, colors):
    hist = run_optimizer(opt, lr=0.1, steps=30)
    losses = [f(pt[0], pt[1]) for pt in hist]

    plt.figure(figsize=(12,5))

    # Path
    plt.subplot(1,2,1)
    plt.contour(X, Y, Z, levels=30, cmap="gray")
    plt.plot(hist[:,0], hist[:,1], marker="o", color=c)
    plt.title(f"Path of {opt.upper()}")
    plt.xlabel("x")
    plt.ylabel("y")

    # Loss
    plt.subplot(1,2,2)
    plt.plot(losses, color=c)
    plt.yscale("log")
    plt.xlabel("Iteration")
    plt.ylabel("Loss (log scale)")
    plt.title(f"Loss curve of {opt.upper()}")

    plt.tight_layout()
    plt.show()



# ***************************************************
#Initialization techniques
import numpy as np
import matplotlib.pyplot as plt

# Simple 1-layer network: y = sigmoid(Wx)
def sigmoid(x): return 1 / (1 + np.exp(-x))

x = np.linspace(-2, 2, 100)

inits = {
    "Zeros": np.zeros((1,)),
    "Random small": np.random.randn(1,) * 0.01,
    "Xavier": np.random.randn(1,) * np.sqrt(1/1),
    "He": np.random.randn(1,) * np.sqrt(2/1)
}

plt.figure(figsize=(8,5))
for name, W in inits.items():
    y = sigmoid(W * x)
    plt.plot(x, y, label=name)

plt.title("Effect of Initialization on Activations")
plt.xlabel("Input")
plt.ylabel("Activation")
plt.legend()
plt.show()


# ***************************************************
# Over fitting,under fitting, bias,variance
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

# ---------------------------
# Generate dataset
# ---------------------------
np.random.seed(42)
X_test = np.linspace(0, 1, 200).reshape(-1,1)
y_true = np.sin(2*np.pi*X_test).ravel()

def generate_data(n=30):
    X = np.random.rand(n,1)
    y = np.sin(2*np.pi*X).ravel() + 0.1*np.random.randn(n)
    return X, y

# ---------------------------
# Show underfit / good fit / overfit
# ---------------------------
X_train, y_train = generate_data()

plt.figure(figsize=(12,4))
for i, deg in enumerate([1, 4, 15], 1):
    poly = PolynomialFeatures(degree=deg)
    X_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)

    model = LinearRegression().fit(X_poly, y_train)
    y_pred = model.predict(X_test_poly)

    plt.subplot(1,3,i)
    plt.scatter(X_train, y_train, color="blue", label="Train data")
    plt.plot(X_test, y_true, "g--", label="True function")
    plt.plot(X_test, y_pred, "r", label=f"Degree={deg}")
    plt.title(f"Degree={deg}")
    plt.legend()

plt.suptitle("Underfitting (deg=1), Good fit (deg=4), Overfitting (deg=15)")
plt.show()

# ---------------------------
# Bias-Variance Decomposition
# ---------------------------
def bias_variance_analysis(max_degree=15, trials=50, n_train=30):
    bias2_list, var_list, error_list = [], [], []

    for deg in range(1, max_degree+1):
        preds = []

        for _ in range(trials):
            X_train, y_train = generate_data(n_train)
            poly = PolynomialFeatures(degree=deg)
            X_poly = poly.fit_transform(X_train)
            X_test_poly = poly.transform(X_test)

            model = LinearRegression().fit(X_poly, y_train)
            preds.append(model.predict(X_test_poly))

        preds = np.array(preds)  # shape: (trials, n_test)
        mean_pred = np.mean(preds, axis=0)

        # Bias^2
        bias2 = np.mean((mean_pred - y_true)**2)
        # Variance
        variance = np.mean(np.var(preds, axis=0))
        # Total Error
        error = np.mean((preds - y_true)**2)

        bias2_list.append(bias2)
        var_list.append(variance)
        error_list.append(error)

    return bias2_list, var_list, error_list

bias2, var, error = bias_variance_analysis(max_degree=15)

# ---------------------------
# Plot Bias-Variance Tradeoff
# ---------------------------
plt.figure(figsize=(8,5))
degrees = range(1,16)
plt.plot(degrees, bias2, label="Bias²", marker="o")
plt.plot(degrees, var, label="Variance", marker="o")
plt.plot(degrees, error, label="Total Error", marker="o")
plt.xlabel("Model Complexity (Polynomial Degree)")
plt.ylabel("Error")
plt.title("Bias-Variance Tradeoff")
plt.legend()
plt.show()


# ***************************************************
# Early stopping,dropout

import numpy as np
import matplotlib.pyplot as plt

# Generate simple dataset
np.random.seed(0)
X = np.linspace(-1,1,200).reshape(-1,1)
y = X**3 + 0.1*np.random.randn(200,1)

# Train/Val split
X_train, y_train = X[:150], y[:150]
X_val, y_val = X[150:], y[150:]

# Simple 1-hidden-layer net
def relu(z): return np.maximum(0,z)
def relu_deriv(z): return (z>0).astype(float)

def train_nn(epochs=2000, lr=0.01, dropout_rate=0.0, early_stop=False):
    np.random.seed(0)
    W1 = np.random.randn(1,20)*0.1
    b1 = np.zeros((1,20))
    W2 = np.random.randn(20,1)*0.1
    b2 = np.zeros((1,1))

    best_val_loss = float("inf")
    patience = 50
    wait = 0

    train_losses, val_losses = [], []

    for epoch in range(epochs):
        # ---- Forward ----
        Z1 = X_train @ W1 + b1
        A1 = relu(Z1)
        # Dropout
        if dropout_rate>0:
            mask = (np.random.rand(*A1.shape) > dropout_rate).astype(float)
            A1 *= mask
            A1 /= (1-dropout_rate)  # scale

        y_pred = A1 @ W2 + b2
        loss = np.mean((y_train - y_pred)**2)

        # Validation
        A1_val = relu(X_val @ W1 + b1)
        y_val_pred = A1_val @ W2 + b2
        val_loss = np.mean((y_val - y_val_pred)**2)

        train_losses.append(loss)
        val_losses.append(val_loss)

        # ---- Backward ----
        dloss = -2*(y_train - y_pred)/len(y_train)
        dW2 = A1.T @ dloss
        db2 = np.sum(dloss, axis=0, keepdims=True)
        dA1 = dloss @ W2.T
        dZ1 = dA1 * relu_deriv(Z1)
        dW1 = X_train.T @ dZ1
        db1 = np.sum(dZ1, axis=0, keepdims=True)

        # Update
        W1 -= lr*dW1; b1 -= lr*db1
        W2 -= lr*dW2; b2 -= lr*db2

        # Early stopping check
        if early_stop:
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                wait = 0
            else:
                wait += 1
                if wait > patience:
                    print(f"Early stopping at epoch {epoch}")
                    break

    return train_losses, val_losses

# --- Run experiments ---
train1, val1 = train_nn(epochs=500, early_stop=False, dropout_rate=0.0)
train2, val2 = train_nn(epochs=500, early_stop=True, dropout_rate=0.0)
train3, val3 = train_nn(epochs=500, early_stop=False, dropout_rate=0.3)

plt.figure(figsize=(12,5))
plt.plot(train1, label="Train (No regularization)")
plt.plot(val1, label="Val (No regularization)")
plt.plot(val2, label="Val (Early stopping)")
plt.plot(val3, label="Val (Dropout=0.3)")
plt.yscale("log")
plt.xlabel("Epochs")
plt.ylabel("MSE Loss")
plt.title("Early Stopping & Dropout comparison")
plt.legend()
plt.show()
